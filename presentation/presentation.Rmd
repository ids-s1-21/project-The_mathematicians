---
title: "Student's Beliefs about Mathematics"
author: "The Mathematicians <br> Alfin Hou, Pietro Rossi and Sandy Braun"
institute: "University of Edinburgh"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r load-packages, include = FALSE}
# Add any additional packages you need to this chunk
library(tidyverse)
library(tidymodels)
library(palmerpenguins)
library(knitr)
library(xaringanthemer)
library(patchwork)
library(gtools)
library(broom)
library(dplyr)
```

```{r setup, include=FALSE}
# For better figure resolution
knitr::opts_chunk$set(fig.retina = 3, dpi = 300, fig.width = 6, fig.asp = 0.618, out.width = "80%")
knitr::opts_knit$set(root.dir = "/cloud/project/data")
```

```{r load-data, include=FALSE}
responses_numeric1_filtered <- read_csv("responses_numeric1_filtered.csv")
responses_numeric2_filtered <- read_csv("responses_numeric2_filtered.csv")
roc_matrix <- read_csv("roc_matrix.csv")
```

```{r style-setting, include=FALSE}
style_mono_light(base_color = "#23395b")
```

## Overall goal & research question

We will be investigating certain beliefs of students towards Mathematics using multiple sub questions:.  

--

1. How are answers distributed between students in different schools?

   (e.g. School of Mathematics vs. School of Informatics)

--

2. Are there any correlations between answers/groups of answers?

   (e.g. whether some combinations of answers to different questions are more likely to be chosen simultaneously)

--

3. How do the answers of students differ from expected answers (answers from experts)?  


---

# Our dats sets

The result of an anonymous survey regarding "Beliefs about Mathematics" which was completed by students of the University of Edinburgh for the academic year 2019-2020 (Data set obtained from Dr. George Kinnear).  

--
  - 32 questions in total (One filter question whose mark doesn't count)
  
  - We also use data sets containing gender, schools and the experts' answers for each question.


---


# Processing data

Before we perform analysis, we need to transfer answers such as "Agree", "Disagree" to numeric answers. There are two methods (we considered) of doing this:  

--

  1. Each student will get 1 mark for answering the question at the same direction as the experts (e.g. "Agree" and "Strongly Agree" is at the same direction as "Agree") and 0 otherwise. 
  
--
  
  2. For questions of which expected answers are "Agree", we could give marks for "Strongly Agree", "Agree", "Neutral", "Disagree" and "Strongly Disagree" as follows: 2, 1, 0, -1, -2. Vice versa.  

---

# Method decision

--

We decided to use the first method because:  

--

As the answer from the experts comes in only two variants ("agree" and ""disagree"), and we cannot know to what degree they actually agree with a choice like the one that's been given to the students (So it doesn't make sense that "Strongly Agree" necessarily earns more marks than "Agree").

---

class: inverse, middle, center

# Analysis results

---

class: inverse, middle, center

# How do the answers of students differ from the expected answers?

---

# Method 

- Based on the first method of converting categorical answers to numeric ones, we generated an "expert-like score" by calculating the sum of mark for each student to show how their answers differ from the expected answers.

--

- Then, from the results, we generated a bar chart showing the number of students in each mark (0 to 31) and a histogram showing the number of people in each percentage of marks.

---

# Graph for "expert-like scores" distribution

```{r plot-for-analysis-I, echo = FALSE, warning = FALSE, out.height = "80%", out.width = "60%"}
include_graphics("https://i.postimg.cc/4d8J4zbM/file-show.png")
```

--

.pull-top[
- The data is <span style="color:red">left-skewed</span>.  
- <span style="color:red">54.7%</span> of students obtained a mark in range 21-27, which is <span style="color:red">67.7%-87.1%</span> of marks (Relatively high level of correspondence with experts.
]

---

class: inverse, middle, center

# How are answers distributed between students in different schools & genders?

---

# Average marks for different schools*

--

```{r plot-for-analysis-2-schools-average, echo = FALSE, out.height = "80%", out.width = "60%"}
responses_numeric1_filtered %>%
  group_by(anon_id) %>%
  summarise(
    individual_mark = sum(mark, na.rm = TRUE),
    programme_school_name = programme_school_name,
    .groups = "keep"
  ) %>%
  distinct() %>%
  filter(programme_school_name %in% c(
    "School of Mathematics",
    "School of Informatics",
    "School of Economics",
    "School of Physics and Astronomy",
    "School of Philosophy, Psychology and Language Sciences"
    )
  ) %>%
  group_by(programme_school_name) %>%
  summarise(avg_mark = mean(individual_mark)) %>%
  ggplot(mapping = aes(x = reorder(programme_school_name, avg_mark), y = avg_mark, fill = programme_school_name)) +
  geom_col() +
  theme_minimal() +
  scale_x_discrete(guide = guide_axis(n.dodge=2)) +
  labs(
    x = "School",
    y = "Average mark",
    title = "Average marks in different school",
    fill = "School name"
  ) +
  theme(axis.text.x = element_blank()) +
  scale_fill_viridis_d() +
  geom_text(mapping = aes(label = signif(avg_mark, digits = 3)), size = 3, position = position_stack(vjust = 1.1))
```

.footnote[
[*] some schools are removed because number of students from this school is too few to draw representative results.
]

---

# Analysis for the rate of correctness for each question 

--

.pull-left[
- They have differences in their average marks.
- They have similar patterns of rates of correctness.
]

.pull-right[

```{r plot-for-analysis-2-schools-question, echo = FALSE, warning = FALSE, out.width = "300%", out.height = "360%"}
responses_numeric1_filtered %>%
  filter(programme_school_name %in% c(
    "School of Mathematics",
    "School of Informatics",
    "School of Economics",
    "School of Physics and Astronomy",
    "School of Philosophy, Psychology and Language Sciences"
    )
  ) %>%
  mutate(programme_school_name = if_else(
    programme_school_name == "School of Philosophy, Psychology and Language Sciences",
    "School of PPL",
    programme_school_name
    )) %>%
  group_by(qnum, programme_school_name) %>%
  summarise(
    percentage_correctness = sum(mark) / n() * 100,
    .groups = "keep"
    ) %>%
  ggplot(mapping = aes(x = qnum, y = percentage_correctness)) +
  geom_col() +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 114)) +
  labs(
    x = "School",
    y = "Question No.",
    title = "Rate of correctness in different school",
    fill = "School name"
  ) +
  facet_wrap(programme_school_name ~ ., ncol = 2, scales = "free") 
```
]
---

# Average marks in different genders

--

```{r plot-for-analysis-2-genders-average, echo = FALSE, out.width = "60%", out.height = "80%"}
responses_numeric1_filtered %>%
  group_by(anon_id) %>%
  summarise(
    individual_mark = sum(mark, na.rm = TRUE),
    gender = gender,
    .groups = "keep"
  ) %>%
  distinct() %>%
  filter(is.na(gender) == FALSE) %>%
  group_by(gender) %>%
  summarise(avg_mark = mean(individual_mark)) %>%
  ggplot(mapping = aes(x = reorder(gender, -avg_mark), y = avg_mark, fill = gender)) +
  geom_col() +
  theme_minimal() +
  labs(
    x = "Gender",
    y = "Average mark",
    title = "Average marks in different gender",
  ) +
  geom_text(mapping = aes(label = signif(avg_mark, digits = 3)), size = 3, position = position_stack(vjust = 1.1))
```

---

# Analysis for the rate of correctness for each gender

--
.pull-text[
- They have similar average marks.
- However, for some questions, males answered better while for some others, females answered better.
]

```{r plot-for-analysis-2-genders-question, echo = FALSE, warning = FALSE, out.width = "50%", out.height = "80%"}
responses_numeric1_filtered %>%
  filter(is.na(gender) == FALSE) %>%
  group_by(qnum, gender) %>%
  summarise(
    percentage_correctness = sum(mark) / n() * 100,
    .groups = "keep"
    ) %>%
  ggplot(mapping = aes(x = as.factor(qnum), y = percentage_correctness)) +
  geom_col() +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 114)) +
  labs(
    x = "Question No.",
    y = "Rate of correctness",
    title = "Rate of correctness in different school",
  ) +
  facet_wrap(gender ~ ., ncol = 1, scales = "free") +
  geom_text(mapping = aes(label = signif(percentage_correctness, digits = 3)), size = 2, position = position_stack(vjust = 1.2)) 
```

---

# Question Comparison

We select the questions where there are significant differences between female scores and make scores.

```{r table-for-analysis-2-genders-question, echo = FALSE, warning = FALSE}
responses_female <- responses_numeric1_filtered %>%
  filter(is.na(gender) == FALSE) %>%
  group_by(qnum, gender) %>%
  summarise(
    percentage_correctness = sum(mark) / n() * 100,
    .groups = "keep"
    ) %>%
  filter(gender == "F")
responses_male <- responses_numeric1_filtered %>%
  filter(is.na(gender) == FALSE) %>%
  group_by(qnum, gender) %>%
  summarise(
    percentage_correctness = sum(mark) / n() * 100,
    .groups = "keep"
    ) %>%
  filter(gender == "M")
difference_marks <- tibble(
  qnum = responses_male$qnum,
  male_mark = responses_male$percentage_correctness,
  female_mark = responses_female$percentage_correctness
) %>%
  mutate(difference = male_mark - female_mark) %>%
  arrange(difference)
difference_marks <- rbind(slice(difference_marks, 1:2), slice(difference_marks, 30:31))
kable(difference_marks, format = "html")
```

--

Question 30: Showing intermediate steps for a math problem is not important as long as I can find the correct answer. (Disagree)    
Question 28: All I need to solve a math problem is to have the necessary formulas. (Disagree)  
Question 8: If I am stuck on a math problem for more than ten minutes, I give up or get help from someone else. (Disagree)    
Question 27: I think it is unfair to expect me to solve a math problem that is not similar to any example given in class or the textbook, even if the topic has been covered in the course. (Disagree)  

---


class: inverse, middle, center

# Are there any correlations between answers/groups of answers?

---

# Categorising questions

Questions are divided into a number of categories* listed below:  

--

- Persistence in Problem Solving: Questions No.8, 10, 24, 29  

- Growth Mindset (Students' belief about whether mathematical ability is innate or can be developed.): Question No.5, 6, 22, 31  

- Interest in Mathematics: Question No.12, 26, 32  

- Relationship between Mathematics and Real World: Question No.13, 15, 21  

- Sense Making (Whether students care about sense making in problem solving): Question No.3, 4, 11, 18, 23 

- Nature of the Answers (Students' views on the nature of solutions to mathematics problems): Question No.2, 7, 9, 16, 28, 30  

- No category: Question No.25, 27 

.footnote[
See Reference in README for support
]
---

# Testing linearity

--

We tested the linear correlation between different categories and generate a pearson correlation coefficient for each pair of categories.

--

It turned out that there is no strong linear correlation (Coefficient < 0.4).

--

```{r table-for-analysis3-linearity, echo = FALSE}
not_finish_list <- responses_numeric1_filtered %>%
  filter(is.na(answer) == TRUE) 
not_finish_list <- as_tibble(unique(not_finish_list$anon_id))
not_finish_list <- not_finish_list %>%
  rename(anon_id = value)

responses_part2 <- anti_join(responses_numeric1_filtered, not_finish_list, by = "anon_id")

responses_summary_part2 <- responses_part2 %>%
  filter(qnum != 19) %>%
  group_by(anon_id, category) %>%
  summarise(sum_category_mark = sum(mark), .groups = "keep")

responses_summary_part2 <- responses_summary_part2 %>%
  pivot_wider(names_from = category, values_from = sum_category_mark)
correlation_matrix <- data.frame(matrix(ncol = 8, nrow = 8))
rownames(correlation_matrix) <- colnames(responses_summary_part2[2:9])
colnames(correlation_matrix) <- colnames(responses_summary_part2[2:9])
for (i in 1:8) {
  for (j in 1:8) {
    x <- responses_summary_part2[i + 1]
    y <- responses_summary_part2[j + 1]
    correlation_matrix[i, j] <- cor(x, y, method = "pearson")
  }
}

correlation_matrix <- correlation_matrix %>%
  select(-c("no_category"))
correlation_matrix <- correlation_matrix[-c(5),]

kable(correlation_matrix, format = "html")
```

---

# Logistic Regression 

Therefore, we decided to use a logistic regression to find stronger correlation.  
We sum up the marks in different categories for each student and we decided that for categories as dependent variables, the mark for each student would be 1 if the mark is higher than a certain number (We called it critical number), otherwise it will be 0.

--

Critical Number are shown as follows:  

  - Confidence in Mathematics: 2
  
  - Persistence in Problem Solving: 2 
  
  - Growth Mindset: 2 
  
  - Interest in Mathematics: 1
  
  - Relationship between Mathematics and Real World: 1 
  
  - Sense Making: 2  
  
  - Nature of the Answers: 3  

---

# Logistic Regression

Then we fit a model for each pair of the categories and calculate the AUC for each model fitted.

```{r table-for-analysis3-logistic, echo = FALSE, warning = FALSE}
model_fitting <- function(responses_binary) {

  #Split the data to training data and testing data
  set.seed(9841)
  data_split <- initial_split(responses_binary, prop = 0.8)
  training_data = training(data_split)
  testing_data = testing(data_split)
    
  
  #Create a recipe
  data_rec <- recipe(
    dep_var ~ indep_var,
    data = training_data
  ) %>%
    step_dummy(all_nominal(), -all_outcomes())
  data_model <- logistic_reg() %>%
    set_engine("glm")
  
  #Create workflow
  data_workflow <- workflow() %>%
    add_model(data_model) %>%
    add_recipe(data_rec)
  data_fit <- data_workflow %>%
    fit(data = training_data)
  
  data_predict <- predict(data_fit, testing_data, type = "prob") %>%
    bind_cols(testing_data)
  
  return(data_predict)
}
roc_matrix <- data.frame(matrix(ncol = 8, nrow = 8))
rownames(roc_matrix) <- colnames(responses_summary_part2[2:9])
colnames(roc_matrix) <- colnames(responses_summary_part2[2:9])

roc_matrix <- roc_matrix %>%
  select(-c("no_category"))
roc_matrix <- roc_matrix[-c(5),]

variable_matrix <- permutations(
  8, 
  2, 
  v = colnames(responses_summary_part2)[2:9], 
  repeats.allowed = FALSE
  ) %>%
  as_tibble() %>%
  filter(V1 != "no_category" & V2 != "no_category") %>%
  as.matrix() %>%
  t() 

for (i in 1:42) {
  variable_col <- variable_matrix[i]
  responses_binary <- responses_summary_part2 %>%
    ungroup() %>%
    select(all_of(c(variable_matrix[1,i], variable_matrix[2,i]))) %>%
    mutate(
      dep_var = case_when(
        as.logical(variable_matrix[1,i] == "confidence") ~ if_else(V1 <= 2, 0, 1),
        as.logical(variable_matrix[1,i] == "growth_mindset") ~ if_else(V1 <= 2, 0, 1),
        as.logical(variable_matrix[1,i] == "interest") ~ if_else(V1 <= 1, 0, 1),
        as.logical(variable_matrix[1,i] == "nature") ~ if_else(V1 <= 3, 0, 1),
        as.logical(variable_matrix[1,i] == "persistence") ~ if_else(V1 <= 2, 0, 1),
        as.logical(variable_matrix[1,i] == "real_world") ~ if_else(V1 <= 1, 0, 1),
        as.logical(variable_matrix[1,i] == "sense") ~ if_else(V1 <= 2, 0, 1)
      )
    ) %>%
    mutate(dep_var = as_factor(dep_var)) %>%
    mutate(indep_var = as_factor(V2)) 
  roc_value <- model_fitting(responses_binary) %>%
  roc_auc(
    truth = dep_var,
    .pred_1,
    event_level = "second"
  )
  roc_matrix[variable_matrix[1,i], variable_matrix[2,i]] <- roc_value$.estimate
}

kable(roc_matrix, format = "html")
```

In this table, rows represent dependent variables and columns represent independent variables.  

We can see that the AUC when interest is the dependent variable and confidence is the independent variable is 0.8321314, which is the highest in the table. So, we will take a look at the model.

---

# Interest ~ Confidence Model

```{r model-for-analysis3-logistic, echo = FALSE}
responses_interest_confidence <- responses_summary_part2 %>%
  ungroup() %>%
  select(interest, confidence) %>%
  mutate(
    interest = as_factor(if_else(interest <= 1, 0, 1)),
    confidence = confidence
  ) 

set.seed(9841)
interest_confidence_split <- initial_split(responses_interest_confidence, prop = 0.8)
interest_confidence_training_data = training(interest_confidence_split)
interest_confidence_testing_data = testing(interest_confidence_split)
interest_confidence_rec <- recipe(
  interest ~ confidence,
  data = interest_confidence_training_data
) %>%
  step_dummy(all_nominal(), -all_outcomes())
interest_confidence_model <- logistic_reg() %>%
  set_engine("glm")
interest_confidence_workflow <- workflow() %>%
  add_model(interest_confidence_model) %>%
  add_recipe(interest_confidence_rec)
interest_confidence_fit <- interest_confidence_workflow %>%
  fit(data = interest_confidence_training_data)
kable(tidy(interest_confidence_fit), format = "html")

```

$p$ is the probability that at least $2/3$ of questions in the category "Interest" are answered correctly, $x$ is the number of questions answered correctly in the category "Confidence".

$$log(\frac{p}{1-p}) = 0.626970x + 0.253635$$
---

# ROC curve for the model

```{r roc-for-analysis3-logistic, echo = FALSE}
predict(interest_confidence_fit, interest_confidence_testing_data, type = "prob") %>%
  bind_cols(interest_confidence_testing_data) %>%
  roc_curve(
    truth = interest,
    .pred_1,
    event_level = "second"
  ) %>%
  autoplot()

```

.pull-text[
The AUC is the area under this curve, and higher AUC in short, represents better prediction made by the model.
]

---

# Feeling adventurous?

- Want to find out more about `xaringan`? See https://slides.yihui.name/xaringan/#1.

- You are welcomed to use the default styling of the slides. In fact, that's what I expect majority of you will do. You will differentiate yourself with the content of your presentation.

- But some of you might want to play around with slide styling. The 
`xaringanthemer` provides some solutions for this that: https://pkg.garrickadenbuie.com/xaringanthemer.

- And if you want more bells and whistles, there is also `xaringanExtra`: https://pkg.garrickadenbuie.com/xaringanExtra.
